{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "private_outputs": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CRyvQ1JmNYQ6"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "import your life\n",
        "'''\n",
        "import numpy as np\n",
        "import io\n",
        "import datetime as date\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "def extract_numbers(df):\n",
        "    '''\n",
        "    this function is to extract the division and device name of the intersection\n",
        "    df: the data frame\n",
        "    '''\n",
        "    # Function to extract numbers from a string\n",
        "    def extract_number(text):\n",
        "        if isinstance(text, str):  # Check if text is a string\n",
        "            match = re.search(r'(\\d{2})-(\\d{4})', text)  # Match pattern 'XX-XXXX' looking for a device code\n",
        "            if match:\n",
        "                return match.group(1), match.group(0)\n",
        "        return None, None  # Return None for both if pattern not found or not a string\n",
        "\n",
        "    # Apply the function to create new columns\n",
        "    extracted_data = df['Device'].apply(lambda x: extract_number(x))\n",
        "    df['Division'], df['Device#'] = zip(*extracted_data)\n",
        "\n",
        "    # Check column 'Intersection' if not found in 'Device'\n",
        "    mask = df['Division'].isnull()  # Mask for rows where 'Division' is NaN\n",
        "    df.loc[mask, 'Division'], df.loc[mask, 'Device#'] = zip(*df.loc[mask, 'Intersection'].apply(lambda x: extract_number(x)))\n",
        "\n",
        "    def extract_numbers_from_D04(text):  # Function to extract division from column 'Group'\n",
        "        if isinstance(text, str):  # Check if text is a string\n",
        "            match = re.search(r'D(\\d+)', text)\n",
        "            if match:\n",
        "                return match.group(1)\n",
        "        return None  # Return None if pattern not found or not a string\n",
        "\n",
        "    df['ColumnD04_numbers'] = df['Group'].apply(extract_numbers_from_D04)\n",
        "    df['Division'] = df.apply(lambda row: row['Division'] if pd.notnull(row['Division']) else extract_numbers_from_D04(row['Group']), axis=1)\n",
        "    df.drop(columns=['ColumnD04_numbers'], inplace=True)  # Drop the temporary column\n",
        "\n",
        "    return df\n"
      ],
      "metadata": {
        "id": "9PdAsVztmeMV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_time_difference(df, time_column='Received'):\n",
        "  '''\n",
        "  to count the total time of the data\n",
        "  df: the data frame\n",
        "  time_column: the column with datetime\n",
        "  '''\n",
        "  # Sort the DataFrame by the time column\n",
        "  df_sorted = df.sort_values(by=time_column)\n",
        "\n",
        "  # Extract time data from the first and last rows\n",
        "  first_time = df_sorted.iloc[0][time_column]\n",
        "  last_time = df_sorted.iloc[-1][time_column]\n",
        "  # Calculate the difference in time\n",
        "  time_difference = last_time - first_time\n",
        "\n",
        "  # Convert the time difference to total seconds\n",
        "  total_seconds = time_difference.total_seconds()\n",
        "\n",
        "  return total_seconds\n"
      ],
      "metadata": {
        "id": "wIxkMHkH4XuP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Reading in the csv file: (note that this does not fix the problem of columns geting cut off) hoping that a different version of python might fix the problem. If not it may be a problem in how some items are quoted\n",
        "csv_file=\"Alarm_Report-2024-07-15_15-47-14.csv\"\n",
        "import csv\n",
        "\n",
        "with open(csv_file, 'r', encoding='utf-8') as file:\n",
        "  reader = csv.reader(file, delimiter=',', quotechar='\"', quoting=csv.QUOTE_MINIMAL)\n",
        "  data = [row for row in reader]"
      ],
      "metadata": {
        "id": "_4wsRSe4T2_y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.DataFrame(data)\n",
        "df.columns = df.iloc[0] #adding the headers\n",
        "df = df[1:]"
      ],
      "metadata": {
        "collapsed": true,
        "id": "o7FTFT7zP3J8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df"
      ],
      "metadata": {
        "id": "MwhiG-PbJ9QV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.columns = ['Received', 'Cleared', 'Severity', 'Name', 'Index', 'Device', 'Intersection', 'Group', 'Description', 'Active', 'Acknowledged', 'Comment', 'col1', 'col2', 'col3', 'col4'] # Set the new column names"
      ],
      "metadata": {
        "id": "MShbw0TsigUJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#rotating columns around based on patterns in the code. Note that I am writing over some data because I only need columns 'Name' 'Active', 'Acknowledged' 'Received', 'Cleared' and 'Device' with 'Intersection', 'Group', 'Description', 'Severity' 'Comment', being helpful.\n",
        "box=[]\n",
        "for c, row in df.iterrows():\n",
        "  if pd.notna(row['col2']): #if the data has entered into col2\n",
        "    if row['Name']==\" Time Drift\": #if time Drift\n",
        "      df.at[c, 'Group'] = df.at[c, 'Active']\n",
        "      df.at[c,'Description'] =df.at[c,'col1']\n",
        "      df.at[c, 'Active'] =df.at[c,'col2']\n",
        "      df.at[c,'Acknowledged']=df.at[c,'col3']\n",
        "      df.at[c,'Comment'] = df.at[c,'col4']\n",
        "      box.append(df.loc[c])\n",
        "    elif row['Name']==\" Database Upload Failed\": #if Database Upload Failed\n",
        "      if pd.notna(row['col4']): #if in col 4\n",
        "        df.at[c, 'Group'] = df.at[c, 'Active']\n",
        "        df.at[c,'Description'] =df.at[c,'Comment']\n",
        "        df.at[c, 'Active'] =df.at[c,'col2']\n",
        "        df.at[c,'Acknowledged']=df.at[c,'col3']\n",
        "        box.append(df.loc[c])\n",
        "      else:\n",
        "        df.at[c, 'Group'] = df.at[c, 'Active']\n",
        "        df.at[c,'Description'] =df.at[c,'Comment']\n",
        "        df.at[c, 'Active'] =df.at[c,'col1']\n",
        "        df.at[c, 'Acknowledged'] =df.at[c,'col2']\n",
        "        df.at[c,'Comment'] = df.at[c,'col3']\n",
        "        box.append(df.loc[c])\n",
        "    else: #if in col 2 but not either of the above, note likely missing some other variance of how the data might split. If it gets fixed at the source that would be better!\n",
        "      df.at[c, 'Group'] = df.at[c, 'Active']\n",
        "      df.at[c,'Description'] =df.at[c,'Acknowledged']\n",
        "      df.at[c,'Comment'] = df.at[c,'col3']\n",
        "      df.at[c, 'Active'] =df.at[c,'col1']\n",
        "      df.at[c,'Acknowledged']=df.at[c,'col2']\n",
        "      box.append(df.loc[c])\n",
        "  elif row['Name']==\" Time Drift\": #this is what the time Drift\n",
        "    df.at[c, 'Description']=df.at[c,'Active']\n",
        "    df.at[c,'Active']=df.at[c,'Acknowledged']\n",
        "    df.at[c,'Acknowledged']=df.at[c,'Comment']\n",
        "    df.at[c,'Comment'] = df.at[c,'col1']\n",
        "    box.append(df.loc[c])\n",
        "  elif row['Name']==\" Database Upload Failed\" and pd.notna(row['col1']): #this is what the Database Upload Failed\n",
        "    df.at[c, 'Description']=df.at[c,'Active']\n",
        "    df.at[c,'Active']=df.at[c,'Acknowledged']\n",
        "    df.at[c, 'Acknowledged'] =df.at[c,'Comment']\n",
        "    df.at[c,'Comment'] = df.at[c,'col1']\n",
        "    box.append(df.loc[c])\n",
        "  else:\n",
        "    box.append(df.loc[c]) #normal (probably)\n",
        "df1 = pd.DataFrame(box)"
      ],
      "metadata": {
        "collapsed": true,
        "id": "iKPld1NvP-L6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df1"
      ],
      "metadata": {
        "id": "XNa9CIXYjZy8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df1['Active'] = df1['Active'].map({' true':True,' false':False,' ':False}) #forcing active and acknowledge to be Boolean\n",
        "df1['Acknowledged'] = df1['Acknowledged'].map({' true':True,' false':False,' ':False})\n",
        "pd.api.types.is_bool_dtype(df1['Acknowledged'])"
      ],
      "metadata": {
        "id": "v1rNwIQtx75W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df2=df1.drop(['col1','col2','col3','col4'],axis=1) #dropping unnamedd columns"
      ],
      "metadata": {
        "collapsed": true,
        "id": "9WYU8Mb9nAjy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df2"
      ],
      "metadata": {
        "id": "ZVlwPKFKHHOS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df2['Received'] = pd.to_datetime(df2['Received'], format=\"%m/%d/%Y %I:%M:%S %p\") #Converting to date time and converting back to UTC\n",
        "df2['Received'] = df2['Received'].dt.tz_localize('Etc/GMT-2')\n",
        "df2['Received'] = df2['Received'].dt.tz_convert('UTC')\n",
        "df2['Cleared'] = pd.to_datetime(df2['Cleared'], format= \" %m/%d/%Y %I:%M:%S %p\", errors='coerce')\n",
        "df2['Cleared'] = df2['Cleared'].dt.tz_localize('Etc/GMT-2')\n",
        "df2['Cleared'] = df2['Cleared'].dt.tz_convert('UTC')"
      ],
      "metadata": {
        "id": "VNr7sRYzxhlg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df2['Duration'] = df2['Cleared'] - df2['Received']"
      ],
      "metadata": {
        "id": "IOBWdiET0t3l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df2 = extract_numbers(df2) #calling the function to extract numbers to get the division and device name of the intersection"
      ],
      "metadata": {
        "id": "pBaObXdGXAGp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df2"
      ],
      "metadata": {
        "id": "kNluAIb32MQr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#getting ready to sort that is row comm failure\n",
        "tohist=[]\n",
        "for c, row in df2.iterrows():\n",
        "  if 'Device#' in row.index:\n",
        "    tohist.append(df2.loc[c, ['Device#','Duration','Name']])\n",
        "tohist = pd.DataFrame(tohist)"
      ],
      "metadata": {
        "id": "jjSamCD7Lkpv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tohist1 = {}\n",
        "# Initialize an empty dictionary to store the transformed data\n",
        "for name in tohist['Device#'].unique():\n",
        "    # Select durations where comm failure\n",
        "    total_duration = tohist.loc[(tohist['Device#'] == name) & (tohist['Name'] == ' Comm Failure'), 'Duration'].sum() #rotating to device name and summing the total duration of comm failure\n",
        "\n",
        "    # Create a new key with the name and corresponding durations\n",
        "    tohist1[name] = total_duration\n",
        "tohist2 = pd.DataFrame(list(tohist1.items()), columns=['Device#', 'Total_Duration'])"
      ],
      "metadata": {
        "id": "pRLWTbnEMUJ_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tohist2['Division'] = tohist2['Device#'].str.extract(r'^(\\d{2})') #add back in the division"
      ],
      "metadata": {
        "id": "fW39T9eGvv1C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tohist2['Total_Duration'] = pd.to_timedelta(tohist2['Total_Duration'], errors='coerce') #convert to time delta"
      ],
      "metadata": {
        "id": "myY3aaKiBHPL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tohist2['percentage_of_time'] = tohist2['Total_Duration'].dt.total_seconds() / calculate_time_difference(df2) * 100 #averge over the whole data frame\n",
        "tohist2 = tohist2.drop(tohist2[tohist2['Division'].isna()].index)"
      ],
      "metadata": {
        "id": "Ouk1rA-l6pxI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tohist2"
      ],
      "metadata": {
        "id": "LS7mbDva1Xf-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df2.to_csv('Alarm Report.csv', sep=',') #write up the initial dataframe"
      ],
      "metadata": {
        "id": "XGi04agdAKu2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tohist2.to_csv('Comm Failure.csv', sep=',') #write the up time"
      ],
      "metadata": {
        "id": "g-1Xp9R8wv_v"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}